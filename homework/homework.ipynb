{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6349692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, balanced_accuracy_score, recall_score, f1_score\n",
    "print(\"Imports completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719fc790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"../files/input/test_data.csv.zip\",index_col=False,compression=\"zip\")\n",
    "train_data = pd.read_csv(\"../files/input/train_data.csv.zip\",index_col=False,compression=\"zip\")\n",
    "print(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595f4109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned\n"
     ]
    }
   ],
   "source": [
    "#paso 1\n",
    "test_data = test_data.rename(columns={'default payment next month': 'default'})\n",
    "train_data = train_data.rename(columns={'default payment next month': 'default'})\n",
    "train_data = train_data.loc[train_data[\"MARRIAGE\"] != 0]\n",
    "train_data = train_data.loc[train_data[\"EDUCATION\"] != 0]\n",
    "test_data = test_data.loc[test_data[\"MARRIAGE\"] != 0]\n",
    "test_data = test_data.loc[test_data[\"EDUCATION\"] != 0]\n",
    "test_data['EDUCATION'] = test_data['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "train_data['EDUCATION'] = train_data['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "test_data=test_data.drop(columns=['ID'])\n",
    "train_data=train_data.drop(columns=['ID'])\n",
    "print(\"Data cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936e127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitted\n"
     ]
    }
   ],
   "source": [
    "x_train=train_data.drop(columns=\"default\")\n",
    "y_train=train_data[\"default\"]\n",
    "x_test=test_data.drop(columns=\"default\")\n",
    "y_test=test_data[\"default\"]\n",
    "print(\"Data splitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0917e72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "numerical_features = [col for col in x_train.columns if col not in categorical_features]\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features),\n",
    "        ('scaler', StandardScaler(), numerical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif)),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', MLPClassifier(random_state=21, max_iter=15000))\n",
    "])\n",
    "print(\"Pipeline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28cebdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Model trained\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "        \"pca__n_components\": [None],\n",
    "        \"feature_selection__k\": [20],\n",
    "        \"classifier__hidden_layer_sizes\": [(50, 30, 40, 60)],\n",
    "        \"classifier__alpha\": [0.26],\n",
    "        'classifier__learning_rate_init': [0.001],\n",
    "    }\n",
    "\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=10, \n",
    "    scoring='balanced_accuracy', \n",
    "    refit=True, \n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fdff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '../files/models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "with gzip.open(\"../files/models/model.pkl.gz\", \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919a26f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas guardadas en: ../files/output/metrics.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    # Métricas\n",
    "    metrics = {\n",
    "        \"type\": \"metrics\",  \n",
    "        \"dataset\": dataset_name,\n",
    "        \"precision\": precision_score(y_true, y_pred, average='binary'),         \n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),          \n",
    "        \"recall\": recall_score(y_true, y_pred, average='binary'),              \n",
    "        \"f1_score\": f1_score(y_true, y_pred, average='binary')                 \n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, 'train')\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, 'test')\n",
    "\n",
    "output_path = \"../files/output/metrics.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  \n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    f.write(json.dumps(train_metrics) + '\\n')  \n",
    "    f.write(json.dumps(test_metrics) + '\\n')  \n",
    "\n",
    "print(f\"Métricas guardadas en: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a97bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_and_save_confusion_matrices(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "   \n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    def format_confusion_matrix(cm, dataset_type):\n",
    "        return {\n",
    "            'type': 'cm_matrix',\n",
    "            'dataset': dataset_type,\n",
    "            'true_0': {\n",
    "                'predicted_0': int(cm[0, 0]),\n",
    "                'predicted_1': int(cm[0, 1])\n",
    "            },\n",
    "            'true_1': {\n",
    "                'predicted_0': int(cm[1, 0]),\n",
    "                'predicted_1': int(cm[1, 1])\n",
    "            }\n",
    "        }\n",
    "\n",
    "    metrics = [\n",
    "        format_confusion_matrix(cm_train, 'train'),\n",
    "        format_confusion_matrix(cm_test, 'test')\n",
    "    ]\n",
    "\n",
    "    \n",
    "    output_path = '../files/output/metrics.json'\n",
    "    with open(output_path, 'a') as f:  \n",
    "        for metric in metrics:\n",
    "            f.write(json.dumps(metric) + '\\n')\n",
    "\n",
    "\n",
    "def main(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    import os\n",
    "    os.makedirs('../files/output', exist_ok=True)\n",
    "\n",
    "    \n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred, 'train')\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred, 'test')\n",
    "\n",
    "    calculate_and_save_confusion_matrices(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "main(model, x_train, x_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
